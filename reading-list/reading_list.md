1. [Neural Lattice Language Models](https://arxiv.org/pdf/1803.05071.pdf) [@buckman2018neural]
2. [Quasi-Recurrent Neural Networks](https://arxiv.org/abs/1611.01576) [@bradbury2016quasi]
3. [Learned in translation: Contextualized word vectors](https://openreview.net/pdf?id=SJTCsqMUf) [@mccann2017learned]
4. [Deep contextualized word representations](https://openreview.net/pdf?id=SJTCsqMUf) [Blogpost](http://allennlp.org/elmo) [@peters2018deep]
5. [Google Vizier: A Service for Black-Box Optimization](http://delivery.acm.org/10.1145/3100000/3098043/p1487-golovin.pdf?ip=161.53.65.243&id=3098043&acc=OA&key=4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E5945DC2EABF3343C&__acm__=1521816060_f8e5a5274dbf83b05b40a09fb442c1dc) [@golovin2017google]
6. [Zoneout: Regularizing RNNs by Randomly Preserving Hidden Activations](https://arxiv.org/pdf/1606.01305.pdf) [@krueger2016zoneout]
7. [Regularization of neural networks using dropconnect](http://proceedings.mlr.press/v28/wan13.pdf) [@wan2013regularization]

# References
